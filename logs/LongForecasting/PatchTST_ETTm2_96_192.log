Args in experiment:
rnn_base_model = 'FreTS'
Namespace(random_seed=2021, is_training=1, model_id='96_192', model='FreTS_baseline', baseline=True, data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=18, pred_len=192, fc_dropout=0.2, head_dropout=0.0, patch_len=96, stride=53, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=1000, patience=8, learning_rate=0.00549, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, momentum=0.9669740372386173, frequency=0.05, sampling_rate=100, use_norm=True, hidden_size=353, exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, partial_start_index=0, top_k=5, num_kernels=6, use_gpu=True, gpu=0, use_multi_gpu=True, devices='0,1', test_flop=False, x=5, rnn_base_model='FreTS', debug=False, dvices='0,1', device_ids=[0, 1])
Use GPU: cuda:0
>>>>>>>start training : 96_192_FreTS_baseline_ETTm2_ftM_sl96_ll18_pl192_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
Epoch: 1 cost time: 5.10371208190918
[2024-04-18 14:42:44] [32mIntermediate result: 0.35896918  (Index 0)[0m
Epoch: 1, Steps: 34 | Train Loss: 0.4865015 Vali Loss: 0.2271859 Test Loss: 0.3589692
Validation loss decreased (inf --> 0.227186).  Saving model ...
Updating learning rate to 0.00022773539541651178
Epoch: 2 cost time: 3.769522190093994
[2024-04-18 14:42:50] [32mIntermediate result: 0.3135358  (Index 1)[0m
Epoch: 2, Steps: 34 | Train Loss: 0.3347264 Vali Loss: 0.2015751 Test Loss: 0.3135358
Validation loss decreased (0.227186 --> 0.201575).  Saving model ...
Updating learning rate to 0.00025209135044368305
Epoch: 3 cost time: 3.766458749771118
[2024-04-18 14:42:56] [32mIntermediate result: 0.31273463  (Index 2)[0m
Epoch: 3, Steps: 34 | Train Loss: 0.3235121 Vali Loss: 0.2013747 Test Loss: 0.3127346
Validation loss decreased (0.201575 --> 0.201375).  Saving model ...
Updating learning rate to 0.0002925174815623212
Epoch: 4 cost time: 3.7652111053466797
[2024-04-18 14:43:02] [32mIntermediate result: 0.3120928  (Index 3)[0m
Epoch: 4, Steps: 34 | Train Loss: 0.3204721 Vali Loss: 0.1996334 Test Loss: 0.3120928
Validation loss decreased (0.201375 --> 0.199633).  Saving model ...
Updating learning rate to 0.0003487641814850749
Epoch: 5 cost time: 3.7648205757141113
[2024-04-18 14:43:07] [32mIntermediate result: 0.30859563  (Index 4)[0m
Epoch: 5, Steps: 34 | Train Loss: 0.3187237 Vali Loss: 0.1983118 Test Loss: 0.3085956
Validation loss decreased (0.199633 --> 0.198312).  Saving model ...
Updating learning rate to 0.0004204841603328126
Epoch: 6 cost time: 3.7974088191986084
[2024-04-18 14:43:13] [32mIntermediate result: 0.34724247  (Index 5)[0m
Epoch: 6, Steps: 34 | Train Loss: 0.3231296 Vali Loss: 0.2144816 Test Loss: 0.3472425
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0005072345899428225
Epoch: 7 cost time: 3.748185157775879
[2024-04-18 14:43:19] [32mIntermediate result: 0.31559065  (Index 6)[0m
Epoch: 7, Steps: 34 | Train Loss: 0.3215241 Vali Loss: 0.2027834 Test Loss: 0.3155906
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.0006084798380690277
Epoch: 8 cost time: 3.7756147384643555
[2024-04-18 14:43:25] [32mIntermediate result: 0.37000266  (Index 7)[0m
Epoch: 8, Steps: 34 | Train Loss: 0.3216397 Vali Loss: 0.2220533 Test Loss: 0.3700027
EarlyStopping counter: 3 out of 8
Updating learning rate to 0.0007235947755921592
Epoch: 9 cost time: 3.8334319591522217
[2024-04-18 14:43:31] [32mIntermediate result: 0.30651733  (Index 8)[0m
Epoch: 9, Steps: 34 | Train Loss: 0.3223830 Vali Loss: 0.2004694 Test Loss: 0.3065173
EarlyStopping counter: 4 out of 8
Updating learning rate to 0.0008518686363198228
Epoch: 10 cost time: 3.7746152877807617
[2024-04-18 14:43:36] [32mIntermediate result: 0.33340314  (Index 9)[0m
Epoch: 10, Steps: 34 | Train Loss: 0.3251169 Vali Loss: 0.2125642 Test Loss: 0.3334031
EarlyStopping counter: 5 out of 8
Updating learning rate to 0.0009925094055445024
Epoch: 11 cost time: 3.875537395477295
[2024-04-18 14:43:42] [32mIntermediate result: 0.4054144  (Index 10)[0m
Epoch: 11, Steps: 34 | Train Loss: 0.3225834 Vali Loss: 0.2323268 Test Loss: 0.4054144
EarlyStopping counter: 6 out of 8
Updating learning rate to 0.0011446487102627668
Epoch: 12 cost time: 3.7920641899108887
[2024-04-18 14:43:48] [32mIntermediate result: 0.42976844  (Index 11)[0m
Epoch: 12, Steps: 34 | Train Loss: 0.3308319 Vali Loss: 0.2459561 Test Loss: 0.4297684
EarlyStopping counter: 7 out of 8
Updating learning rate to 0.001307347180861472
Epoch: 13 cost time: 3.8015427589416504
[2024-04-18 14:43:54] [32mIntermediate result: 0.52032334  (Index 12)[0m
Epoch: 13, Steps: 34 | Train Loss: 0.3149246 Vali Loss: 0.2750082 Test Loss: 0.5203233
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 96_192_FreTS_baseline_ETTm2_ftM_sl96_ll18_pl192_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.30859553813934326, mae:0.3797469437122345, rse:0.44635266065597534
[2024-04-18 14:43:55] [32mFinal result: 0.30859554[0m
