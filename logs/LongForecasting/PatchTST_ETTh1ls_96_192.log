Args in experiment:
rnn_base_model = 'PatchTST_real'
Namespace(random_seed=2021, is_training=1, model_id='96_192', model='PatchTST', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, fc_dropout=0.3, head_dropout=0.0, patch_len=48, stride=48, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=258, patience=8, learning_rate=0.001545, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, momentum=0.9669740372386173, frequency=0.05, sampling_rate=100, use_norm=True, hidden_size=651, exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, partial_start_index=0, top_k=5, num_kernels=6, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', test_flop=False, x=5, rnn_base_model='PatchTST_real', debug=True, feature_in=1)
Use GPU: cuda:0
>>>>>>>start training : 96_192_PatchTST_ETTh1_ftM_sl96_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
IN exp_main.py
batch_x.shape = torch.Size([258, 96, 7])
batch_x_mark.shape = torch.Size([258, 96, 4])
dec_inp.shape = torch.Size([258, 240, 7])
batch_y_mark.shape = torch.Size([258, 240, 4])
********************
IN PatchTST_backbone.py
batch_x.shape = torch.Size([258, 7, 96])
batch_x_mark.shape = torch.Size([258, 4, 96])
dec_inp.shape = torch.Size([258, 7, 240])
batch_y_mark.shape = torch.Size([258, 4, 240])

patches_batch_x.shape = torch.Size([258, 7, 2, 48])
patches_batch_x_mark.shape = torch.Size([258, 4, 2, 48])
patches_dec_inp.shape = torch.Size([258, 7, 5, 48])
patches_batch_y_mark.shape = torch.Size([258, 4, 5, 48])

patches_batch_x.shape = torch.Size([1806, 2, 48])
patches_batch_x_mark.shape = torch.Size([1032, 2, 48])
patches_dec_inp.shape = torch.Size([1806, 5, 48])
patches_batch_y_mark.shape = torch.Size([1032, 5, 48])
IN rnn.py
[0]before tanh: h.shape = torch.Size([1806, 1, 651])
IN PatchTST_real.py
before backbone: x.shape = torch.Size([1806, 1, 48])
IN PatchTST_backbone_real.py
in: z.shape = torch.Size([1806, 48, 1])
after permute: z.shape = torch.Size([1806, 1, 48])
before unfold: z.shape = torch.Size([1806, 1, 96])
after unfold&permute: z.shape = torch.Size([1806, 1, 48, 2])
after backbone: z.shape = torch.Size([1806, 1, 16, 2])
after head: z.shape = torch.Size([1806, 1, 651])
out: z.shape = torch.Size([1806, 651, 1])

after backbone: x.shape = torch.Size([1806, 1, 651])

IN PatchTST_real.py
before backbone: x.shape = torch.Size([1806, 1, 651])
IN PatchTST_backbone_real.py
in: z.shape = torch.Size([1806, 651, 1])
after permute: z.shape = torch.Size([1806, 1, 651])
before unfold: z.shape = torch.Size([1806, 1, 699])
after unfold&permute: z.shape = torch.Size([1806, 1, 48, 14])
after backbone: z.shape = torch.Size([1806, 1, 16, 14])
after head: z.shape = torch.Size([1806, 1, 651])
out: z.shape = torch.Size([1806, 651, 1])

after backbone: x.shape = torch.Size([1806, 1, 651])

[0]after tanh: h.shape = torch.Size([1806, 1, 651])
[1]before tanh: h.shape = torch.Size([1806, 1, 1, 651])
IN PatchTST_real.py
before backbone: x.shape = torch.Size([1806, 1, 48])
IN PatchTST_backbone_real.py
in: z.shape = torch.Size([1806, 48, 1])
after permute: z.shape = torch.Size([1806, 1, 48])
before unfold: z.shape = torch.Size([1806, 1, 96])
after unfold&permute: z.shape = torch.Size([1806, 1, 48, 2])
after backbone: z.shape = torch.Size([1806, 1, 16, 2])
after head: z.shape = torch.Size([1806, 1, 651])
out: z.shape = torch.Size([1806, 651, 1])

after backbone: x.shape = torch.Size([1806, 1, 651])

IN PatchTST_real.py
before backbone: x.shape = torch.Size([1806, 1, 1, 651])
