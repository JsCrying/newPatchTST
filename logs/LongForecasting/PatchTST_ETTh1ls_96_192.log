Args in experiment:
rnn_base_model = 'PatchTST_real'
Namespace(random_seed=2021, is_training=1, model_id='96_192', model='PatchTST', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, fc_dropout=0.3, head_dropout=0.0, patch_len=96, stride=53, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=258, patience=8, learning_rate=0.001545, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, momentum=0.9669740372386173, frequency=0.05, sampling_rate=100, use_norm=True, hidden_size=651, exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, partial_start_index=0, top_k=5, num_kernels=6, use_gpu=True, gpu=0, use_multi_gpu=True, devices='0,1', test_flop=False, x=5, rnn_base_model='PatchTST_real', debug=False, feature_in=1, dvices='0,1', device_ids=[0, 1])
Use GPU: cuda:0
>>>>>>>start training : 96_192_PatchTST_ETTh1_ftM_sl96_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
Epoch: 1 cost time: 6.044498682022095
[2024-04-15 17:13:35] [32mIntermediate result: 1.0533526  (Index 0)[0m
Epoch: 1, Steps: 32 | Train Loss: 1.0274674 Vali Loss: 1.4392936 Test Loss: 1.0533526
Validation loss decreased (inf --> 1.439294).  Saving model ...
Updating learning rate to 0.001545
Epoch: 2 cost time: 2.6907386779785156
[2024-04-15 17:13:39] [32mIntermediate result: 0.9463013  (Index 1)[0m
Epoch: 2, Steps: 32 | Train Loss: 0.9651212 Vali Loss: 1.2623190 Test Loss: 0.9463013
Validation loss decreased (1.439294 --> 1.262319).  Saving model ...
Updating learning rate to 0.001545
Epoch: 3 cost time: 2.911801815032959
[2024-04-15 17:13:44] [32mIntermediate result: 0.9206468  (Index 2)[0m
Epoch: 3, Steps: 32 | Train Loss: 0.9040806 Vali Loss: 1.2482522 Test Loss: 0.9206468
Validation loss decreased (1.262319 --> 1.248252).  Saving model ...
Updating learning rate to 0.001545
Epoch: 4 cost time: 2.9394662380218506
[2024-04-15 17:13:48] [32mIntermediate result: 0.9708683  (Index 3)[0m
Epoch: 4, Steps: 32 | Train Loss: 0.8641491 Vali Loss: 1.2485359 Test Loss: 0.9708683
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0013905
Epoch: 5 cost time: 2.955117702484131
[2024-04-15 17:13:53] [32mIntermediate result: 0.9822075  (Index 4)[0m
Epoch: 5, Steps: 32 | Train Loss: 0.8428192 Vali Loss: 1.2463790 Test Loss: 0.9822075
Validation loss decreased (1.248252 --> 1.246379).  Saving model ...
Updating learning rate to 0.00125145
Epoch: 6 cost time: 2.7678449153900146
[2024-04-15 17:13:57] [32mIntermediate result: 0.97948515  (Index 5)[0m
Epoch: 6, Steps: 32 | Train Loss: 0.8305406 Vali Loss: 1.2316375 Test Loss: 0.9794852
Validation loss decreased (1.246379 --> 1.231637).  Saving model ...
Updating learning rate to 0.0011263050000000002
Epoch: 7 cost time: 2.7491610050201416
[2024-04-15 17:14:02] [32mIntermediate result: 0.9784969  (Index 6)[0m
Epoch: 7, Steps: 32 | Train Loss: 0.8252041 Vali Loss: 1.2299268 Test Loss: 0.9784969
Validation loss decreased (1.231637 --> 1.229927).  Saving model ...
Updating learning rate to 0.0010136745
Epoch: 8 cost time: 2.8657195568084717
[2024-04-15 17:14:06] [32mIntermediate result: 0.99481905  (Index 7)[0m
Epoch: 8, Steps: 32 | Train Loss: 0.8203609 Vali Loss: 1.2308791 Test Loss: 0.9948190
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.00091230705
Epoch: 9 cost time: 2.818727493286133
[2024-04-15 17:14:11] [32mIntermediate result: 1.0065753  (Index 8)[0m
Epoch: 9, Steps: 32 | Train Loss: 0.8154117 Vali Loss: 1.2268183 Test Loss: 1.0065753
Validation loss decreased (1.229927 --> 1.226818).  Saving model ...
Updating learning rate to 0.000821076345
Epoch: 10 cost time: 2.832763910293579
[2024-04-15 17:14:15] [32mIntermediate result: 0.99624  (Index 9)[0m
Epoch: 10, Steps: 32 | Train Loss: 0.8109214 Vali Loss: 1.2181756 Test Loss: 0.9962400
Validation loss decreased (1.226818 --> 1.218176).  Saving model ...
Updating learning rate to 0.0007389687105000001
Epoch: 11 cost time: 2.9916837215423584
[2024-04-15 17:14:20] [32mIntermediate result: 0.9773844  (Index 10)[0m
Epoch: 11, Steps: 32 | Train Loss: 0.8101774 Vali Loss: 1.2210974 Test Loss: 0.9773844
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0006650718394500001
Epoch: 12 cost time: 2.8161368370056152
[2024-04-15 17:14:25] [32mIntermediate result: 0.989184  (Index 11)[0m
Epoch: 12, Steps: 32 | Train Loss: 0.8069815 Vali Loss: 1.2158633 Test Loss: 0.9891840
Validation loss decreased (1.218176 --> 1.215863).  Saving model ...
Updating learning rate to 0.0005985646555050001
Epoch: 13 cost time: 2.8719329833984375
[2024-04-15 17:14:29] [32mIntermediate result: 1.0085092  (Index 12)[0m
Epoch: 13, Steps: 32 | Train Loss: 0.8027949 Vali Loss: 1.2283822 Test Loss: 1.0085092
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0005387081899545001
Epoch: 14 cost time: 2.871431827545166
[2024-04-15 17:14:34] [32mIntermediate result: 0.9987504  (Index 13)[0m
Epoch: 14, Steps: 32 | Train Loss: 0.8019095 Vali Loss: 1.2308342 Test Loss: 0.9987504
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.00048483737095905005
