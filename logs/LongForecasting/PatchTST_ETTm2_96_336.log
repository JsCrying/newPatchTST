Args in experiment:
rnn_base_model = 'FreTS'
Namespace(random_seed=2021, is_training=1, model_id='96_336', model='FreTS_baseline', baseline=True, data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=18, pred_len=336, fc_dropout=0.2, head_dropout=0.0, patch_len=96, stride=53, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=1000, patience=8, learning_rate=0.00549, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, momentum=0.9669740372386173, frequency=0.05, sampling_rate=100, use_norm=True, hidden_size=353, exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, partial_start_index=0, top_k=5, num_kernels=6, use_gpu=True, gpu=0, use_multi_gpu=True, devices='0,1', test_flop=False, x=5, rnn_base_model='FreTS', debug=False, dvices='0,1', device_ids=[0, 1])
Use GPU: cuda:0
>>>>>>>start training : 96_336_FreTS_baseline_ETTm2_ftM_sl96_ll18_pl336_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
Epoch: 1 cost time: 5.360860824584961
[2024-04-18 14:44:07] [32mIntermediate result: 0.5066095  (Index 0)[0m
Epoch: 1, Steps: 34 | Train Loss: 0.6165799 Vali Loss: 0.3163833 Test Loss: 0.5066095
Validation loss decreased (inf --> 0.316383).  Saving model ...
Updating learning rate to 0.00022773539541651178
Epoch: 2 cost time: 4.025243759155273
[2024-04-18 14:44:13] [32mIntermediate result: 0.477168  (Index 1)[0m
Epoch: 2, Steps: 34 | Train Loss: 0.4301936 Vali Loss: 0.2976911 Test Loss: 0.4771680
Validation loss decreased (0.316383 --> 0.297691).  Saving model ...
Updating learning rate to 0.00025209135044368305
Epoch: 3 cost time: 4.074791431427002
[2024-04-18 14:44:19] [32mIntermediate result: 0.42267275  (Index 2)[0m
Epoch: 3, Steps: 34 | Train Loss: 0.4174846 Vali Loss: 0.2720110 Test Loss: 0.4226727
Validation loss decreased (0.297691 --> 0.272011).  Saving model ...
Updating learning rate to 0.0002925174815623212
Epoch: 4 cost time: 3.985322952270508
[2024-04-18 14:44:26] [32mIntermediate result: 0.46802223  (Index 3)[0m
Epoch: 4, Steps: 34 | Train Loss: 0.4164103 Vali Loss: 0.2883541 Test Loss: 0.4680222
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0003487641814850749
Epoch: 5 cost time: 3.993834972381592
[2024-04-18 14:44:32] [32mIntermediate result: 0.38411883  (Index 4)[0m
Epoch: 5, Steps: 34 | Train Loss: 0.4099700 Vali Loss: 0.2551714 Test Loss: 0.3841188
Validation loss decreased (0.272011 --> 0.255171).  Saving model ...
Updating learning rate to 0.0004204841603328126
Epoch: 6 cost time: 3.985976457595825
[2024-04-18 14:44:38] [32mIntermediate result: 0.49123573  (Index 5)[0m
Epoch: 6, Steps: 34 | Train Loss: 0.4075303 Vali Loss: 0.2943430 Test Loss: 0.4912357
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0005072345899428225
Epoch: 7 cost time: 4.059411287307739
[2024-04-18 14:44:44] [32mIntermediate result: 0.50869465  (Index 6)[0m
Epoch: 7, Steps: 34 | Train Loss: 0.4053177 Vali Loss: 0.3018219 Test Loss: 0.5086946
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.0006084798380690277
Epoch: 8 cost time: 3.99025559425354
[2024-04-18 14:44:51] [32mIntermediate result: 0.43789232  (Index 7)[0m
Epoch: 8, Steps: 34 | Train Loss: 0.4067543 Vali Loss: 0.2713357 Test Loss: 0.4378923
EarlyStopping counter: 3 out of 8
Updating learning rate to 0.0007235947755921592
Epoch: 9 cost time: 4.010905504226685
[2024-04-18 14:44:57] [32mIntermediate result: 0.432075  (Index 8)[0m
Epoch: 9, Steps: 34 | Train Loss: 0.4053567 Vali Loss: 0.2715500 Test Loss: 0.4320750
EarlyStopping counter: 4 out of 8
Updating learning rate to 0.0008518686363198228
Epoch: 10 cost time: 4.071473836898804
[2024-04-18 14:45:03] [32mIntermediate result: 0.51295304  (Index 9)[0m
Epoch: 10, Steps: 34 | Train Loss: 0.4040559 Vali Loss: 0.3070583 Test Loss: 0.5129530
EarlyStopping counter: 5 out of 8
Updating learning rate to 0.0009925094055445024
Epoch: 11 cost time: 3.997127056121826
[2024-04-18 14:45:09] [32mIntermediate result: 0.43641055  (Index 10)[0m
Epoch: 11, Steps: 34 | Train Loss: 0.3965948 Vali Loss: 0.2668279 Test Loss: 0.4364105
EarlyStopping counter: 6 out of 8
Updating learning rate to 0.0011446487102627668
Epoch: 12 cost time: 4.035296201705933
[2024-04-18 14:45:16] [32mIntermediate result: 0.48242995  (Index 11)[0m
Epoch: 12, Steps: 34 | Train Loss: 0.3835643 Vali Loss: 0.2806470 Test Loss: 0.4824300
EarlyStopping counter: 7 out of 8
Updating learning rate to 0.001307347180861472
Epoch: 13 cost time: 4.03666877746582
[2024-04-18 14:45:22] [32mIntermediate result: 0.43864545  (Index 12)[0m
Epoch: 13, Steps: 34 | Train Loss: 0.3740286 Vali Loss: 0.2675628 Test Loss: 0.4386455
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 96_336_FreTS_baseline_ETTm2_ftM_sl96_ll18_pl336_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3841187655925751, mae:0.4235343933105469, rse:0.49850961565971375
[2024-04-18 14:45:24] [32mFinal result: 0.38411877[0m
