Args in experiment:
rnn_base_model = 'PatchTST_real'
Namespace(random_seed=2021, is_training=1, model_id='96_96', model='PatchTST', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, fc_dropout=0.3, head_dropout=0.0, patch_len=94, stride=53, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=4, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=100, patience=8, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, momentum=0.9669740372386173, frequency=0.05, sampling_rate=100, use_norm=True, hidden_size=128, exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, partial_start_index=0, top_k=5, num_kernels=6, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', test_flop=False, x=5, rnn_base_model='PatchTST_real', debug=False, feature_in=1)
Use GPU: cuda:0
>>>>>>>start training : 96_96_PatchTST_ETTh2_ftM_sl96_ll48_pl96_dm128_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
Epoch: 1 cost time: 8.949206829071045
[2024-04-15 18:05:35] [32mIntermediate result: 3.1938984  (Index 0)[0m
Epoch: 1, Steps: 84 | Train Loss: 1.0731854 Vali Loss: 1.5521704 Test Loss: 3.1938984
Validation loss decreased (inf --> 1.552170).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 9.256999731063843
[2024-04-15 18:05:45] [32mIntermediate result: 3.1364975  (Index 1)[0m
Epoch: 2, Steps: 84 | Train Loss: 1.0197713 Vali Loss: 1.4909254 Test Loss: 3.1364975
Validation loss decreased (1.552170 --> 1.490925).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 9.091826677322388
[2024-04-15 18:05:56] [32mIntermediate result: 3.1324904  (Index 2)[0m
Epoch: 3, Steps: 84 | Train Loss: 0.9885222 Vali Loss: 1.4773189 Test Loss: 3.1324904
Validation loss decreased (1.490925 --> 1.477319).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 9.033523797988892
[2024-04-15 18:06:07] [32mIntermediate result: 3.1276503  (Index 3)[0m
Epoch: 4, Steps: 84 | Train Loss: 0.9794600 Vali Loss: 1.4791238 Test Loss: 3.1276503
EarlyStopping counter: 1 out of 8
Updating learning rate to 9e-05
