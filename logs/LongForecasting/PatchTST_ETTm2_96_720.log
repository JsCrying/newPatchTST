Args in experiment:
rnn_base_model = 'FreTS'
Namespace(random_seed=2021, is_training=1, model_id='96_720', model='FreTS_baseline', baseline=True, data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=18, pred_len=720, fc_dropout=0.2, head_dropout=0.0, patch_len=96, stride=53, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=1000, patience=8, learning_rate=0.00549, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, momentum=0.9669740372386173, frequency=0.05, sampling_rate=100, use_norm=True, hidden_size=353, exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, partial_start_index=0, top_k=5, num_kernels=6, use_gpu=True, gpu=0, use_multi_gpu=True, devices='0,1', test_flop=False, x=5, rnn_base_model='FreTS', debug=False, dvices='0,1', device_ids=[0, 1])
Use GPU: cuda:0
>>>>>>>start training : 96_720_FreTS_baseline_ETTm2_ftM_sl96_ll18_pl720_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
Epoch: 1 cost time: 5.782938718795776
[2024-04-18 14:45:36] [32mIntermediate result: 0.67715573  (Index 0)[0m
Epoch: 1, Steps: 33 | Train Loss: 0.7667844 Vali Loss: 0.4315728 Test Loss: 0.6771557
Validation loss decreased (inf --> 0.431573).  Saving model ...
Updating learning rate to 0.0002277357580485126
Epoch: 2 cost time: 4.396003484725952
[2024-04-18 14:45:43] [32mIntermediate result: 0.58227456  (Index 1)[0m
Epoch: 2, Steps: 33 | Train Loss: 0.5451639 Vali Loss: 0.3842495 Test Loss: 0.5822746
Validation loss decreased (0.431573 --> 0.384250).  Saving model ...
Updating learning rate to 0.000252092796493515
Epoch: 3 cost time: 4.4791364669799805
[2024-04-18 14:45:50] [32mIntermediate result: 0.67717296  (Index 2)[0m
Epoch: 3, Steps: 33 | Train Loss: 0.5357123 Vali Loss: 0.4180375 Test Loss: 0.6771730
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0002925207184227693
Epoch: 4 cost time: 4.391648292541504
[2024-04-18 14:45:57] [32mIntermediate result: 0.46132022  (Index 3)[0m
Epoch: 4, Steps: 33 | Train Loss: 0.5286956 Vali Loss: 0.3332966 Test Loss: 0.4613202
Validation loss decreased (0.384250 --> 0.333297).  Saving model ...
Updating learning rate to 0.000348769894365099
Epoch: 5 cost time: 4.452671766281128
[2024-04-18 14:46:04] [32mIntermediate result: 0.5086736  (Index 4)[0m
Epoch: 5, Steps: 33 | Train Loss: 0.5282612 Vali Loss: 0.3519453 Test Loss: 0.5086736
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0004204930036724357
Epoch: 6 cost time: 4.483856678009033
[2024-04-18 14:46:11] [32mIntermediate result: 0.5323652  (Index 5)[0m
Epoch: 6, Steps: 33 | Train Loss: 0.5228056 Vali Loss: 0.3537364 Test Loss: 0.5323652
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.0005072471791135926
Epoch: 7 cost time: 4.44068169593811
[2024-04-18 14:46:19] [32mIntermediate result: 0.56342983  (Index 6)[0m
Epoch: 7, Steps: 33 | Train Loss: 0.5210012 Vali Loss: 0.3673644 Test Loss: 0.5634298
EarlyStopping counter: 3 out of 8
Updating learning rate to 0.0006084967414375936
Epoch: 8 cost time: 4.456468105316162
[2024-04-18 14:46:26] [32mIntermediate result: 0.8039328  (Index 7)[0m
Epoch: 8, Steps: 33 | Train Loss: 0.5194622 Vali Loss: 0.4525642 Test Loss: 0.8039328
EarlyStopping counter: 4 out of 8
Updating learning rate to 0.0007236165070214975
Epoch: 9 cost time: 4.445146799087524
[2024-04-18 14:46:33] [32mIntermediate result: 0.6617333  (Index 8)[0m
Epoch: 9, Steps: 33 | Train Loss: 0.5338646 Vali Loss: 0.4008433 Test Loss: 0.6617333
EarlyStopping counter: 5 out of 8
Updating learning rate to 0.0008518956481790635
Epoch: 10 cost time: 4.469052791595459
[2024-04-18 14:46:40] [32mIntermediate result: 0.75761896  (Index 9)[0m
Epoch: 10, Steps: 33 | Train Loss: 0.5184805 Vali Loss: 0.4369934 Test Loss: 0.7576190
EarlyStopping counter: 6 out of 8
Updating learning rate to 0.0009925420822940725
Epoch: 11 cost time: 4.399701833724976
[2024-04-18 14:46:47] [32mIntermediate result: 0.478311  (Index 10)[0m
Epoch: 11, Steps: 33 | Train Loss: 0.5167193 Vali Loss: 0.3450228 Test Loss: 0.4783110
EarlyStopping counter: 7 out of 8
Updating learning rate to 0.001144687362676828
Epoch: 12 cost time: 4.463364839553833
[2024-04-18 14:46:54] [32mIntermediate result: 0.5932652  (Index 11)[0m
Epoch: 12, Steps: 33 | Train Loss: 0.5140799 Vali Loss: 0.3650066 Test Loss: 0.5932652
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 96_720_FreTS_baseline_ETTm2_ftM_sl96_ll18_pl720_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.4613191783428192, mae:0.467545747756958, rse:0.5436466336250305
[2024-04-18 14:46:56] [32mFinal result: 0.46131918[0m
