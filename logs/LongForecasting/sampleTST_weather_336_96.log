Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='336_96', model='sampleTST', data='custom', root_path='./dataset/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=21, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=8, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, momentum=0.9669740372386173, frequency=0.05, sampling_rate=100, use_gpu=True, gpu=0, use_multi_gpu=True, devices='0,1', test_flop=False, x=5, dvices='0,1', device_ids=[0, 1])
Use GPU: cuda:0
>>>>>>>start training : 336_96_sampleTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36456
val 5175
test 10444
	iters: 100, epoch: 1 | loss: 0.5941943
	speed: 0.0521s/iter; left time: 1475.2999s
	iters: 200, epoch: 1 | loss: 0.5317804
	speed: 0.0279s/iter; left time: 787.1925s
Epoch: 1 cost time: 10.434150218963623
[2024-02-29 22:31:11] [32mIntermediate result: 0.24808465  (Index 0)[0m
Epoch: 1, Steps: 284 | Train Loss: 0.6633510 Vali Loss: 0.5970249 Test Loss: 0.2480846
Validation loss decreased (inf --> 0.597025).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7421200
	speed: 0.0876s/iter; left time: 2454.7548s
	iters: 200, epoch: 2 | loss: 0.4258980
	speed: 0.0268s/iter; left time: 749.0978s
Epoch: 2 cost time: 8.053920030593872
[2024-02-29 22:31:22] [32mIntermediate result: 0.1798219  (Index 1)[0m
Epoch: 2, Steps: 284 | Train Loss: 0.4874415 Vali Loss: 0.4459137 Test Loss: 0.1798219
Validation loss decreased (0.597025 --> 0.445914).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.5925891
	speed: 0.0836s/iter; left time: 2319.2802s
	iters: 200, epoch: 3 | loss: 0.6039617
	speed: 0.0266s/iter; left time: 734.8451s
Epoch: 3 cost time: 8.054492235183716
[2024-02-29 22:31:33] [32mIntermediate result: 0.17565459  (Index 2)[0m
Epoch: 3, Steps: 284 | Train Loss: 0.4644957 Vali Loss: 0.4400767 Test Loss: 0.1756546
Validation loss decreased (0.445914 --> 0.440077).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.8072250
	speed: 0.0865s/iter; left time: 2374.0080s
	iters: 200, epoch: 4 | loss: 0.6738774
	speed: 0.0267s/iter; left time: 730.1893s
Epoch: 4 cost time: 8.099174976348877
[2024-02-29 22:31:45] [32mIntermediate result: 0.17531969  (Index 3)[0m
Epoch: 4, Steps: 284 | Train Loss: 0.4621283 Vali Loss: 0.4370179 Test Loss: 0.1753197
Validation loss decreased (0.440077 --> 0.437018).  Saving model ...
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.3188397
	speed: 0.0878s/iter; left time: 2384.9375s
	iters: 200, epoch: 5 | loss: 0.3534327
	speed: 0.0283s/iter; left time: 766.1860s
Epoch: 5 cost time: 8.194957494735718
[2024-02-29 22:31:56] [32mIntermediate result: 0.17857723  (Index 4)[0m
Epoch: 5, Steps: 284 | Train Loss: 0.4611572 Vali Loss: 0.4392321 Test Loss: 0.1785772
EarlyStopping counter: 1 out of 8
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.6228711
	speed: 0.0852s/iter; left time: 2290.4504s
	iters: 200, epoch: 6 | loss: 0.3749174
	speed: 0.0262s/iter; left time: 701.4305s
